p8105_hw3_rh3195
================
Ruijie He
2023-10-14

## Problem 1

``` r
data("instacart")

instacart = 
  instacart |> 
  as_tibble()
```

> This dataset contains 1384617 rows, which represents the ordered
> items. And it contains 1384617 columns. Some key variables specifies
> the informations of each order, like `order_number`, `product_name`,
> `aisle`, `department`, and `order_dow`. They tells the time of the
> orders placed and some purchase activities for each product. In this
> dataset, there are 39123 products found in 131209 orders from 131209
> distinct users.

**Aisle number**

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

    ## # A tibble: 134 × 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ℹ 124 more rows

> There are 134 aisles, and the aisle has the most items is the fresh
> vegetables aisle.

**Make a plot (aisle has \>10000)**

``` r
aisle_plot = 
  instacart %>% 
  janitor::clean_names() %>% 
  count(aisle) %>% 
  filter(n>10000) %>% 
  ggplot(aes( x= reorder(aisle, n), y = n)) +
  geom_point() +
  labs(
    title = "Number of Items",
    x = "Aisle number",
    y = "Number of item",
    caption = "Data from instacart online grocery shopping dataset 2017"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

> The plot shows the number of items in selected aisles in an ascending
> order. Only aisles that contains more than 10000 items were selected.

**Three most popular items table**

``` r
popular_items =
  instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(number_of_ordered_times = n()) %>% 
  arrange(aisle, -number_of_ordered_times) %>% 
  do(top_n(., 3, wt = number_of_ordered_times))

popular_items_table =
  knitr::kable(popular_items,
      col.names = c("Aisle", "Product name", "Number of ordered times"),
      title = "The 3 Most popular items in selected aisle")
```

> This table shows the three most popular item in `baking ingredients`,
> `dog food care`, and `packaged vegetables fruits` and lists the number
> of times each has been ordered.

**A 2 x 7 table**

As the `order_dow` tells the day of the week the order was placed on.

``` r
mean_hour =
  instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) %>% 

knitr::kable(digits = 3,
             title = "Mean Hour Ordered of Selected Items")
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the
    ## `.groups` argument.

``` r
mean_hour
```

| product_name     |      0 |      1 |      2 |      3 |      4 |      5 |      6 |
|:-----------------|-------:|-------:|-------:|-------:|-------:|-------:|-------:|
| Coffee Ice Cream | 13.774 | 14.316 | 15.381 | 15.318 | 15.217 | 12.263 | 13.833 |
| Pink Lady Apples | 13.441 | 11.360 | 11.702 | 14.250 | 11.552 | 12.784 | 11.938 |

> Above table shows the mean hour of the day at which Pink Lady Apples
> and Coffee Ice Cream are ordered on each day of the week. The variable
> `order_dow` tells the day of the week the order was placed on. The
> table has been `pivot_wider` to format for human readers. Pink lady
> apple were bought slightly earlier in the day 1, 2, 4, 6 each week
> than coffee ice cream. And both items were likely to be bought in the
> afternoon.

## Problem 2

``` r
library(p8105.datasets)
data("brfss_smart2010")
```

**Data cleaning**

``` r
brfss_df =
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health",
         response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% 
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), order = TRUE)) %>% 
  rename("state" = "locationabbr") %>% 
  select(topic, response, everything())

brfss_df
```

    ## # A tibble: 10,625 × 23
    ##    topic response  year state locationdesc class question sample_size data_value
    ##    <chr> <ord>    <int> <chr> <chr>        <chr> <chr>          <int>      <dbl>
    ##  1 Over… Excelle…  2010 AL    AL - Jeffer… Heal… How is …          94       18.9
    ##  2 Over… Very go…  2010 AL    AL - Jeffer… Heal… How is …         148       30  
    ##  3 Over… Good      2010 AL    AL - Jeffer… Heal… How is …         208       33.1
    ##  4 Over… Fair      2010 AL    AL - Jeffer… Heal… How is …         107       12.5
    ##  5 Over… Poor      2010 AL    AL - Jeffer… Heal… How is …          45        5.5
    ##  6 Over… Excelle…  2010 AL    AL - Mobile… Heal… How is …          91       15.6
    ##  7 Over… Very go…  2010 AL    AL - Mobile… Heal… How is …         177       31.3
    ##  8 Over… Good      2010 AL    AL - Mobile… Heal… How is …         224       31.2
    ##  9 Over… Fair      2010 AL    AL - Mobile… Heal… How is …         120       15.5
    ## 10 Over… Poor      2010 AL    AL - Mobile… Heal… How is …          66        6.4
    ## # ℹ 10,615 more rows
    ## # ℹ 14 more variables: confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

> The cleaned dataset is focusing on `topic` of “overall health” and
> only includes `responses` from “excellent” to “poor”.

**States observed at \>= 7 locations in 2002 and 2010**

``` r
states_observed_2002 =
  brfss_df %>% 
  filter(year == 2002) %>% 
  group_by(state) %>% 
  summarize(n_observation = n_distinct(locationdesc)) %>% 
  filter(n_observation > 6) %>% 
  arrange(desc(n_observation))

states_observed_2002
```

    ## # A tibble: 6 × 2
    ##   state n_observation
    ##   <chr>         <int>
    ## 1 PA               10
    ## 2 MA                8
    ## 3 NJ                8
    ## 4 CT                7
    ## 5 FL                7
    ## 6 NC                7

> In 2002, the states that were observed at 7 or more locations are PA,
> MA, NJ, CT, NC, and FL.

``` r
states_observed_2010 =
  brfss_df %>% 
  filter(year == 2010) %>% 
  group_by(state) %>%
  summarize(n_observation = n_distinct(locationdesc)) %>% 
  filter(n_observation > 6) %>% 
  arrange(desc(n_observation))

states_observed_2010
```

    ## # A tibble: 14 × 2
    ##    state n_observation
    ##    <chr>         <int>
    ##  1 FL               41
    ##  2 NJ               19
    ##  3 TX               16
    ##  4 CA               12
    ##  5 MD               12
    ##  6 NC               12
    ##  7 NE               10
    ##  8 WA               10
    ##  9 MA                9
    ## 10 NY                9
    ## 11 OH                8
    ## 12 CO                7
    ## 13 PA                7
    ## 14 SC                7

> In 2010, 14 states were observed at 7 or more locations, which are FL,
> NJ, TX, CA, MD, NC, NE, WA, MA, NY.
